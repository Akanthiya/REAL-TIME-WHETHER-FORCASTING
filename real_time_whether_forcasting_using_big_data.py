# -*- coding: utf-8 -*-
"""REAL TIME WHETHER FORCASTING USING BIG DATA

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ds-CYu0NjjB8SLHtAOtkF2ilStgNXWjM
"""

import numpy as np
import pandas as pd

# Simulate weather data collection (IoT sensors, weather APIs, etc.)
def collect_data(n_samples=1000):
     # Simulated data: temperature, humidity, wind speed, and pressure
      data = {
"temperature": np.random.uniform(20, 35, n_samples),# Temperature in Celsius
"humidity": np.random.uniform(30, 90, n_samples),# Humidity in percentage
"pressure": np.random.uniform(1000, 1025, n_samples), # Atmospheric pressure it hPa
"wind_speed": np.random.uniform(0, 15, n_samples),# Wind speed in km/h
"rainfall": np.random.uniform(0, 10, n_samples),# Rainfall in mm
"location": np.random.choice(["Area 1", "Area 2", "Area 3"], n_samples)# Location/Region
      }
      df = pd.DataFrame(data)
      return df
# Collect simulated data
weather_data = collect_data(n_samples=1000)
print(weather_data.head()) # Show the first few rows of collected data

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler

# Data Preprocessing
def preprocess_data(df):
    # Handle missing values (if any)
    df = df.dropna()  # Drop rows with missing values

    # Convert categorical columns to numerical (if any)
    df['location'] = pd.Categorical(df['location']).codes  # Convert location to numeric codes

    # Normalize numerical features (temperature, humidity, etc.)
    scaler = MinMaxScaler()
    numerical_features = ['temperature', 'humidity', 'pressure', 'wind_speed', 'rainfall']
    df[numerical_features] = scaler.fit_transform(df[numerical_features])

    # Split the data into features (X) and target (y)
    X = df[numerical_features]  # Features
    y = df['rainfall']  # Target: Predict rainfall

    # Split into training and testing sets
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

    return X_train, X_test, y_train, y_test

# Preprocess the weather data
X_train, X_test, y_train, y_test = preprocess_data(weather_data)
print(f"Training Data: {X_train.shape}, Test Data: {X_test.shape}")  # Show the shape of the datasets

from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error

# Train the prediction model
def train_model(X_train, y_train):
    model = RandomForestRegressor(n_estimators=100, random_state=42)
    model.fit(X_train, y_train)
    return model

# Evaluate the model
def evaluate_model(model, X_test, y_test):
    y_pred = model.predict(X_test)
    mse = mean_squared_error(y_test, y_pred)
    print(f"Mean Squared Error (MSE): {mse}")
    return mse

# Train the model and evaluate
model = train_model(X_train, y_train)
evaluate_model(model, X_test, y_test)

import joblib

# Save the trained model
def save_model(model, filename='weather_forecast_model.pkl'):
    joblib.dump(model, filename)
    print(f"Model saved as {filename}")

# Save the model
save_model(model)

# Real-time prediction (future step)
def make_prediction(model, new_data):
    prediction = model.predict(new_data)
    return prediction

# Example: Predict rainfall for new weather data (hypothetical input)
new_data = np.array([[0.8, 0.7, 0.5, 0.2, 0.1]])  # Example feature values (normalized)
predicted_rainfall = make_prediction(model, new_data)
print(f"Predicted Rainfall: {predicted_rainfall}")

pip install tensorflow pandas numpy matplotlib scikit-learn

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.preprocessing import MinMaxScaler
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense

# 1. Load the weather data
# Replace this with real-time API data in a real system
data_url = "https://raw.githubusercontent.com/jbrownlee/Datasets/master/daily-min-temperatures.csv"
data = pd.read_csv(data_url)
data['Date'] = pd.to_datetime(data['Date'])
data.set_index('Date', inplace=True)

# 2. Preprocessing
scaler = MinMaxScaler(feature_range=(0, 1))
scaled_data = scaler.fit_transform(data[['Temp']].values)

# Split data into training and test sets
train_size = int(len(scaled_data) * 0.8)
train_data, test_data = scaled_data[:train_size], scaled_data[train_size:]

# Create sequences
def create_sequences(data, time_steps):
    X, y = [], []
    for i in range(len(data) - time_steps):
        X.append(data[i:i + time_steps])
        y.append(data[i + time_steps])
    return np.array(X), np.array(y)

time_steps = 30
X_train, y_train = create_sequences(train_data, time_steps)
X_test, y_test = create_sequences(test_data, time_steps)

# 3. Build the RNN Model (LSTM)
model = Sequential([
    LSTM(50, return_sequences=True, input_shape=(X_train.shape[1], 1)),
    LSTM(50, return_sequences=False),
    Dense(25),
    Dense(1)
])

model.compile(optimizer='adam', loss='mean_squared_error')

# 4. Train the Model
model.fit(X_train, y_train, batch_size=32, epochs=10, verbose=1)

# 5. Make Predictions
predictions = model.predict(X_test)
predictions = scaler.inverse_transform(predictions)
y_test_actual = scaler.inverse_transform(y_test.reshape(-1, 1))

# 6. Visualize the Predictions
plt.figure(figsize=(10, 6))
plt.plot(data.index[-len(y_test):], y_test_actual, label="Actual Temperature")
plt.plot(data.index[-len(y_test):], predictions, label="Predicted Temperature")
plt.title("Temperature Forecasting with RNN (LSTM)")
plt.xlabel("Date")
plt.ylabel("Temperature")
plt.legend()
plt.show()

pip install pandas numpy matplotlib tensorflow scikit-learn

# Simulating spatially distributed temperature data (e.g., multiple regions)
np.random.seed(0)

# Assume we have temperature data for 5 regions over 100 days
n_regions = 5
n_days = 100

# Create random temperature data for each region over 100 days
dates = pd.date_range(start='2022-01-01', periods=n_days, freq='D')
regions = [f'Region_{i+1}' for i in range(n_regions)]

# Random data generation for temperature
temperature_data = np.random.uniform(low=15, high=35, size=(n_days, n_regions))

# Create a DataFrame with this simulated data
data = pd.DataFrame(temperature_data, columns=regions, index=dates)

# Plot the data
data.plot(figsize=(12, 6))
plt.title("Simulated Temperature Data for Multiple Regions")
plt.xlabel("Date")
plt.ylabel("Temperature (Â°C)")
plt.show()

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.preprocessing import MinMaxScaler
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense
from sklearn.metrics import mean_squared_error

# Normalize the data to a range between 0 and 1 for better performance of LSTM
scaler = MinMaxScaler(feature_range=(0, 1))
scaled_data = scaler.fit_transform(data.values)

# Function to create sequences (sliding window)
def create_sequences(data, time_steps):
    X, y = [], []
    for i in range(len(data) - time_steps):
        X.append(data[i:i + time_steps])
        y.append(data[i + time_steps])
    return np.array(X), np.array(y)

# Time steps: e.g., use data from the last 30 days to predict the next day's temperature
time_steps = 30
X, y = create_sequences(scaled_data, time_steps)

# Reshape data for LSTM: (samples, time_steps, features)
X = X.reshape((X.shape[0], X.shape[1], X.shape[2]))  # Time steps, features (regions)

# Build the LSTM model
model = Sequential([
    LSTM(64, return_sequences=True, input_shape=(X.shape[1], X.shape[2])),  # Input is (time_steps, regions)
    LSTM(64),
    Dense(32),
    Dense(1)  # Single output (predicting temperature for the next day)
])

model.compile(optimizer='adam', loss='mean_squared_error')

# Train the model
model.fit(X, y, batch_size=32, epochs=20, verbose=1)

!pip install dash

!pip install dash dash-bootstrap-components pandas plotly tensorflow scikit-learn

import dash
import dash_bootstrap_components as dbc
from dash import dcc, html, Input, Output
import pandas as pd
import numpy as np
import plotly.express as px
from sklearn.preprocessing import MinMaxScaler
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense

# Initialize Dash app with a dark theme
app = dash.Dash(__name__, external_stylesheets=[dbc.themes.CYBORG])

# Simulated temperature data (100 days for 5 regions)
np.random.seed(0)
n_regions = 5
n_days = 100
dates = pd.date_range(start='2022-01-01', periods=n_days, freq='D')
regions = [f'Region_{i+1}' for i in range(n_regions)]
temperature_data = np.random.uniform(low=15, high=35, size=(n_days, n_regions))
data = pd.DataFrame(temperature_data, columns=regions, index=dates)

# Data preprocessing
scaler = MinMaxScaler(feature_range=(0, 1))
scaled_data = scaler.fit_transform(data.values)

# Function to create sequences for LSTM
def create_sequences(data, time_steps):
    X, y = [], []
    for i in range(len(data) - time_steps):
        X.append(data[i:i + time_steps])
        y.append(data[i + time_steps])
    return np.array(X), np.array(y)

time_steps = 30
X, y = create_sequences(scaled_data, time_steps)
X = X.reshape((X.shape[0], X.shape[1], X.shape[2]))

# LSTM Model
model = Sequential([
    LSTM(64, return_sequences=True, input_shape=(X.shape[1], X.shape[2])),
    LSTM(64),
    Dense(32),
    Dense(n_regions)
])

model.compile(optimizer='adam', loss='mean_squared_error')
model.fit(X, y, batch_size=32, epochs=10, verbose=1)
print("âœ… Model training complete!")

# Dash Layout
app.layout = dbc.Container([
    dbc.Row([
        dbc.Col(html.H1("ğŸŒ¤ Hyperlocal Weather Forecast", className="text-center text-primary mb-4"), width=12)
    ]),

    # Region Selection & Predicted Temperature Display
    dbc.Row([
        # Region Dropdown
        dbc.Col(
            dbc.Card([
                dbc.CardBody([
                    html.H5("Select a Region", className="card-title"),
                    dcc.Dropdown(
                        id='region-dropdown',
                        options=[{'label': region, 'value': region} for region in regions],
                        value=regions[0],
                        className="mb-2"
                    )
                ])
            ], className="shadow-lg mb-4"), width=4
        ),

        # Predicted Temperature Display Box
        dbc.Col(
            dbc.Card([
                dbc.CardBody([
                    html.H5("Predicted Temperature (Â°C)", className="card-title text-center"),
                    html.Div(
                        id="predicted-temp",
                        className="text-center text-warning fs-1 p-3 border border-light rounded",
                        style={"backgroundColor": "#222", "width": "100%", "margin": "auto"}
                    )
                ])
            ], className="shadow-lg mb-4"), width=4
        ),
    ]),

    # Forecast Graph
    dbc.Row([
        dbc.Col(
            dbc.Card([
                dbc.CardBody([
                    dcc.Graph(id='forecast-graph')
                ])
            ], className="shadow-lg mb-4")
        )
    ])
], fluid=True)

# Callback to update forecast graph and predicted temperature
@app.callback(
    [Output('forecast-graph', 'figure'), Output('predicted-temp', 'children')],
    [Input('region-dropdown', 'value')]
)
def update_graph(selected_region):
    try:
        region_index = regions.index(selected_region)
        recent_data = scaled_data[-30:].reshape(1, 30, n_regions)

        print(f"ğŸ” Input shape: {recent_data.shape}")

        prediction = model.predict(recent_data)
        print(f"ğŸ“Š Raw Prediction: {prediction}")

        if prediction is not None and len(prediction) > 0:
            region_prediction = prediction[0, region_index]
            region_prediction = scaler.inverse_transform([[region_prediction]])[0][0]
            print(f"ğŸŒ¡ Final Temperature: {region_prediction:.2f}Â°C")

            # Generate a simple forecast graph
            fig = px.line(
                x=dates[-30:],
                y=[region_prediction] * 30,
                labels={'x': 'Date', 'y': 'Temperature (Â°C)'},
                title=f"Predicted Temperature for {selected_region}"
            )

            return fig, f"{region_prediction:.2f}Â°C"
        else:
            return px.line(title="Error: No prediction generated"), "N/A"

    except Exception as e:
        print(f"âŒ Error: {e}")
        return px.line(title="Error: Unable to generate the graph"), "N/A"

# Run the app
if __name__ == '__main__':
    app.run_server(debug=True)

@app.callback(
    Output('forecast-graph', 'figure'),
    [Input('region-dropdown', 'value')]
)
def update_graph(selected_region):
    # Get the index of the selected region
    region_index = regions.index(selected_region)

    # Use the latest available data for the selected region to predict the next day's temperature
    recent_data = scaled_data[-30:].reshape(1, 30, n_regions)  # Using last 30 days of data for all regions

    # Make prediction using the trained LSTM model
    prediction = model.predict(recent_data)

    # Inverse transform the prediction and actual data to get original scale (temperature in Â°C)
    prediction = scaler.inverse_transform(prediction)

    # Plot the forecasted data for the selected region
    fig = px.line(
        x=dates[-30:],
        y=prediction.flatten(),
        labels={'x': 'Date', 'y': 'Temperature (Â°C)'},
        title=f"Predicted Temperature for {selected_region}"
    )

    return fig

import dash
import dash_bootstrap_components as dbc
from dash import dcc, html, Input, Output
import pandas as pd
import numpy as np
import plotly.express as px
from sklearn.preprocessing import MinMaxScaler
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense

# Initialize the Dash app
app = dash.Dash(__name__, external_stylesheets=[dbc.themes.BOOTSTRAP])

# Simulate spatially distributed temperature data for multiple regions
np.random.seed(0)
n_regions = 5
n_days = 100
dates = pd.date_range(start='2022-01-01', periods=n_days, freq='D')
regions = [f'Region_{i+1}' for i in range(n_regions)]
temperature_data = np.random.uniform(low=15, high=35, size=(n_days, n_regions))
data = pd.DataFrame(temperature_data, columns=regions, index=dates)

# Preprocess the data (Scaling and creating sequences for LSTM)
scaler = MinMaxScaler(feature_range=(0, 1))
scaled_data = scaler.fit_transform(data.values)

# Function to create sequences for LSTM
def create_sequences(data, time_steps):
    X, y = [], []
    for i in range(len(data) - time_steps):
        X.append(data[i:i + time_steps])
        y.append(data[i + time_steps])
    return np.array(X), np.array(y)

time_steps = 30
X, y = create_sequences(scaled_data, time_steps)
X = X.reshape((X.shape[0], X.shape[1], X.shape[2]))  # (samples, time_steps, features)

# Build the LSTM model
model = Sequential([
    LSTM(64, return_sequences=True, input_shape=(X.shape[1], X.shape[2])),
    LSTM(64),
    Dense(32),
    Dense(1)  # Single output (temperature for next day)
])

model.compile(optimizer='adam', loss='mean_squared_error')
model.fit(X, y, batch_size=32, epochs=20, verbose=1)

# App Layout
app.layout = dbc.Container([
    dbc.Row([
        dbc.Col(html.H1("Real-Time Hyperlocal Weather Forecasting"), width={'size': 6, 'offset': 3}),
    ]),
    dbc.Row([
        dbc.Col(html.Div("Select a region to view the forecast:"), width=4),
        dbc.Col(dcc.Dropdown(
            id='region-dropdown',
            options=[{'label': region, 'value': region} for region in regions],
            value=regions[0],  # Default value
            multi=False
        ), width=8)
    ]),
    dbc.Row([
        dbc.Col(dcc.Graph(id='forecast-graph'), width=12)
    ])
], fluid=True)

# Callback for updating the forecast graph
@app.callback(
    Output('forecast-graph', 'figure'),
    [Input('region-dropdown', 'value')]
)
def update_graph(selected_region):
    # Get the index of the selected region
    region_index = regions.index(selected_region)

    # Use the latest available data for the selected region to predict the next day's temperature
    recent_data = scaled_data[-30:].reshape(1, 30, n_regions)  # Using last 30 days of data for all regions

    # Make prediction using the trained LSTM model
    prediction = model.predict(recent_data)

    # Inverse transform the prediction and actual data to get original scale (temperature in Â°C)
    prediction = scaler.inverse_transform(prediction)

    # Plot the forecasted data for the selected region
    fig = px.line(
        x=dates[-30:],
        y=prediction.flatten(),
        labels={'x': 'Date', 'y': 'Temperature (Â°C)'},
        title=f"Predicted Temperature for {selected_region}"
    )

    return fig

# Run the app
if __name__ == '__main__':
    app.run_server(debug=True)

import dash
import dash_bootstrap_components as dbc
from dash import dcc, html, Input, Output
import pandas as pd
import numpy as np
import plotly.express as px
from sklearn.preprocessing import MinMaxScaler
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense
from sklearn.metrics import mean_squared_error

# Initialize the Dash app
app = dash.Dash(__name__, external_stylesheets=[dbc.themes.BOOTSTRAP])

# Simulate spatially distributed temperature data for multiple regions
np.random.seed(0)
n_regions = 5
n_days = 100
dates = pd.date_range(start='2022-01-01', periods=n_days, freq='D')
regions = [f'Region_{i+1}' for i in range(n_regions)]
temperature_data = np.random.uniform(low=15, high=35, size=(n_days, n_regions))
data = pd.DataFrame(temperature_data, columns=regions, index=dates)

# Preprocess the data (Scaling and creating sequences for LSTM)
scaler = MinMaxScaler(feature_range=(0, 1))
scaled_data = scaler.fit_transform(data.values)

# Function to create sequences for LSTM
def create_sequences(data, time_steps):
    X, y = [], []
    for i in range(len(data) - time_steps):
        X.append(data[i:i + time_steps])
        y.append(data[i + time_steps])
    return np.array(X), np.array(y)

time_steps = 30
X, y = create_sequences(scaled_data, time_steps)
X = X.reshape((X.shape[0], X.shape[1], X.shape[2]))  # (samples, time_steps, features)

# Build the LSTM model
model = Sequential([
    LSTM(64, return_sequences=True, input_shape=(X.shape[1], X.shape[2])),
    LSTM(64),
    Dense(32),
    Dense(1)  # Single output (temperature for next day)
])

model.compile(optimizer='adam', loss='mean_squared_error')
model.fit(X, y, batch_size=32, epochs=20, verbose=1)

# App Layout
app.layout = dbc.Container([
    dbc.Row([
        dbc.Col(html.H1("Real-Time Hyperlocal Weather Forecasting"), width={'size': 6, 'offset': 3}),
    ]),
    dbc.Row([
        dbc.Col(html.Div("Select a region to view the forecast:"), width=4),
        dbc.Col(dcc.Dropdown(
            id='region-dropdown',
            options=[{'label': region, 'value': region} for region in regions],
            value=regions[0],  # Default value
            multi=False
        ), width=8)
    ]),
    dbc.Row([
        dbc.Col(dcc.Graph(id='forecast-graph'), width=12)
    ])
], fluid=True)

# Callback for updating the forecast graph
@app.callback(
    Output('forecast-graph', 'figure'),
    [Input('region-dropdown', 'value')]
)
def update_graph(selected_region):
    # Get the index of the selected region
    region_index = regions.index(selected_region)

    # Use the latest available data for the selected region to predict the next day's temperature
    recent_data = scaled_data[-30:].reshape(1, 30, n_regions)  # Using last 30 days of data for all regions

    # Debugging: Print the shape of the input data to make sure it's correct
    print(f"Input shape to model: {recent_data.shape}")

    # Make prediction using the trained LSTM model
    prediction = model.predict(recent_data)

    # Debugging: Print the shape and the prediction result
    print(f"Prediction shape: {prediction.shape}")
    print(f"Prediction: {prediction}")

    # Inverse transform the prediction to get temperature in Â°C
    prediction = scaler.inverse_transform(prediction)

    # Debugging: Print the inverse transformed prediction
    print(f"Inverse transformed prediction: {prediction}")

    # Plot the forecasted data for the selected region
    fig = px.line(
        x=dates[-30:],
        y=prediction.flatten(),
        labels={'x': 'Date', 'y': 'Temperature (Â°C)'},
        title=f"Predicted Temperature for {selected_region}"
    )

    return fig

# Run the app
if __name__ == '__main__':
    app.run_server(debug=True)

@app.callback(
    Output('forecast-graph', 'figure'),
    [Input('region-dropdown', 'value')]
)
def update_graph(selected_region):
    try:
        # Get the index of the selected region
        region_index = regions.index(selected_region)

        # Use the latest available data for prediction
        recent_data = scaled_data[-30:].reshape(1, 30, n_regions)  # Last 30 days, all regions

        # Debugging: Print the shape of recent data
        print(f"Input shape to model: {recent_data.shape}")

        # Make prediction using the trained LSTM model
        prediction = model.predict(recent_data)

        # Debugging: Print the shape and values of the prediction
        print(f"Prediction shape: {prediction.shape}")
        print(f"Prediction values: {prediction}")

        # Inverse transform the prediction
        prediction = scaler.inverse_transform(prediction)

        # Debugging: Print the final prediction values
        print(f"Inverse transformed prediction: {prediction}")

        # Plot the forecasted data
        fig = px.line(
            x=dates[-30:],  # Dates for the last 30 days
            y=prediction.flatten(),  # Flattened prediction values
            labels={'x': 'Date', 'y': 'Temperature (Â°C)'},
            title=f"Predicted Temperature for {selected_region}"
        )
        return fig

    except Exception as e:
        print(f"Error in callback: {str(e)}")
        return px.line(title="Error: Unable to generate the graph")

recent_data = scaled_data[-30:].reshape(1, 30, n_regions)

@app.callback(
    Output('forecast-graph', 'figure'),
    [Input('region-dropdown', 'value')]
)
def update_graph(selected_region):
    try:
        # Get the index of the selected region
        region_index = regions.index(selected_region)

        # Ensure recent_data shape matches model input requirements: (1, time_steps, features)
        recent_data = scaled_data[-30:]  # Get the last 30 days of data
        recent_data = recent_data.reshape(1, 30, n_regions)  # Reshape to (1, time_steps, features)

        # Debugging: Print input shape to the model
        print(f"Input shape to model: {recent_data.shape}")  # Expected: (1, 30, n_regions)

        # Make prediction using the trained LSTM model
        prediction = model.predict(recent_data)

        # Debugging: Print prediction output
        print(f"Prediction shape: {prediction.shape}")  # Expected: (1, n_regions)
        print(f"Prediction values: {prediction}")

        # Extract the prediction for the selected region
        region_prediction = prediction[0, region_index]  # Get the value for the selected region

        # Inverse transform the prediction to get temperature in original scale
        region_prediction = scaler.inverse_transform([[region_prediction]])

        # Debugging: Print inverse transformed prediction
        print(f"Inverse transformed prediction for {selected_region}: {region_prediction}")

        # Plot the forecasted value for the selected region as a single forecasted point
        fig = px.line(
            x=dates[-30:],  # Dates for the last 30 days
            y=[region_prediction[0][0]] * 30,  # Use the predicted value for the entire 30-day range
            labels={'x': 'Date', 'y': 'Temperature (Â°C)'},
            title=f"Predicted Temperature for {selected_region}"
        )

        return fig

    except Exception as e:
        # Debugging: Print error details in case of an exception
        print(f"Error in callback: {str(e)}")
        return px.line(title="Error: Unable to generate the graph")

import dash
import dash_bootstrap_components as dbc
from dash import dcc, html, Input, Output
import pandas as pd
import numpy as np
import plotly.express as px
from sklearn.preprocessing import MinMaxScaler
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense

# Initialize the Dash app
app = dash.Dash(__name__, external_stylesheets=[dbc.themes.BOOTSTRAP])

# Simulate spatially distributed temperature data for multiple regions
np.random.seed(0)
n_regions = 5
n_days = 100
dates = pd.date_range(start='2022-01-01', periods=n_days, freq='D')
regions = [f'Region_{i+1}' for i in range(n_regions)]
temperature_data = np.random.uniform(low=15, high=35, size=(n_days, n_regions))
data = pd.DataFrame(temperature_data, columns=regions, index=dates)

# Preprocess the data (Scaling and creating sequences for LSTM)
scaler = MinMaxScaler(feature_range=(0, 1))
scaled_data = scaler.fit_transform(data.values)

# Function to create sequences for LSTM
def create_sequences(data, time_steps):
    X, y = [], []
    for i in range(len(data) - time_steps):
        X.append(data[i:i + time_steps])
        y.append(data[i + time_steps])
    return np.array(X), np.array(y)

time_steps = 30
X, y = create_sequences(scaled_data, time_steps)
X = X.reshape((X.shape[0], X.shape[1], X.shape[2]))  # (samples, time_steps, features)

# Build the LSTM model
model = Sequential([
    LSTM(64, return_sequences=True, input_shape=(X.shape[1], X.shape[2])),
    LSTM(64),
    Dense(32),
    Dense(n_regions)  # Output temperature for all regions
])

model.compile(optimizer='adam', loss='mean_squared_error')
model.fit(X, y, batch_size=32, epochs=10, verbose=1)

# App Layout
app.layout = dbc.Container([
    dbc.Row([
        dbc.Col(html.H1("Real-Time Hyperlocal Weather Forecasting"), width={'size': 6, 'offset': 3}),
    ]),
    dbc.Row([
        dbc.Col(html.Div("Select a region to view the forecast:"), width=4),
        dbc.Col(dcc.Dropdown(
            id='region-dropdown',
            options=[{'label': region, 'value': region} for region in regions],
            value=regions[0],  # Default value
            multi=False
        ), width=8)
    ]),
    dbc.Row([
        dbc.Col(dcc.Graph(id='forecast-graph'), width=12)
    ])
], fluid=True)

# Callback for updating the forecast graph
@app.callback(
    Output('forecast-graph', 'figure'),
    [Input('region-dropdown', 'value')]
)
def update_graph(selected_region):
    try:
        # Get the index of the selected region
        region_index = regions.index(selected_region)

        # Ensure recent_data shape matches model input requirements: (1, time_steps, features)
        recent_data = scaled_data[-30:]  # Get the last 30 days of data
        recent_data = recent_data.reshape(1, 30, n_regions)  # Reshape to (1, time_steps, features)

        # Debugging: Print input shape to the model
        print(f"Input shape to model: {recent_data.shape}")  # Expected: (1, 30, n_regions)

        # Make prediction using the trained LSTM model
        prediction = model.predict(recent_data)

        # Debugging: Print prediction output
        print(f"Prediction shape: {prediction.shape}")  # Expected: (1, n_regions)
        print(f"Prediction values: {prediction}")

        # Extract the prediction for the selected region
        region_prediction = prediction[0, region_index]  # Get the value for the selected region

        # Inverse transform the prediction to get temperature in original scale
        region_prediction = scaler.inverse_transform([[region_prediction]])

        # Debugging: Print inverse transformed prediction
        print(f"Inverse transformed prediction for {selected_region}: {region_prediction}")

        # Create a figure with the predicted temperature
        fig = px.line(
            x=dates[-30:],  # Use the last 30 days of dates
            y=[region_prediction[0][0]] * 30,  # Use the predicted value for simplicity
            labels={'x': 'Date', 'y': 'Temperature (Â°C)'},
            title=f"Predicted Temperature for {selected_region}"
        )

        return fig

    except Exception as e:
        # Debugging: Print error details in case of an exception
        print(f"Error in callback: {str(e)}")
        return px.line(title="Error: Unable to generate the graph")

# Run the app
if __name__ == '__main__':
    app.run_server(debug=True)

@app.callback(
    Output('forecast-graph', 'figure'),
    [Input('region-dropdown', 'value')]
)
def update_graph(selected_region):
    try:
        # Get the index of the selected region
        region_index = regions.index(selected_region)
        print(f"Selected Region: {selected_region}, Index: {region_index}")

        # Prepare the input data for prediction
        recent_data = scaled_data[-30:]  # Get the last 30 days
        recent_data = recent_data.reshape(1, 30, n_regions)  # Reshape for LSTM
        print(f"Input data shape for model: {recent_data.shape}")

        # Make prediction using the trained model
        prediction = model.predict(recent_data)
        print(f"Prediction shape: {prediction.shape}, Prediction values: {prediction}")

        # Extract the prediction for the selected region
        region_prediction = prediction[0, region_index]
        print(f"Raw prediction for {selected_region}: {region_prediction}")

        # Inverse transform the prediction to the original scale
        region_prediction = scaler.inverse_transform([[region_prediction]])
        print(f"Inverse transformed prediction for {selected_region}: {region_prediction}")

        # Create the graph
        fig = px.line(
            x=dates[-30:],  # Dates for the last 30 days
            y=[region_prediction[0][0]] * 30,  # Repeat the predicted value
            labels={'x': 'Date', 'y': 'Temperature (Â°C)'},
            title=f"Predicted Temperature for {selected_region}"
        )
        return fig

    except Exception as e:
        # Print detailed error message
        print(f"Error in callback: {e}")
        return px.line(title="Error: Unable to generate the graph")

pip install dash dash-bootstrap-components pandas plotly tensorflow scikit-learn

pip install dash dash-bootstrap-components

!pip install dash dash-bootstrap-components pandas numpy plotly scikit-learn tensorflow

import dash
import dash_bootstrap_components as dbc
from dash import dcc, html, Input, Output
import pandas as pd
import numpy as np
import plotly.express as px
from sklearn.preprocessing import MinMaxScaler
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense

# Initialize Dash app
app = dash.Dash(__name__, external_stylesheets=[dbc.themes.CYBORG])

# Simulated temperature data
np.random.seed(42)
n_regions = 5
n_days = 100
dates = pd.date_range(start='2022-01-01', periods=n_days, freq='D')
regions = [f'Region_{i+1}' for i in range(n_regions)]
temperature_data = np.random.uniform(low=15, high=35, size=(n_days, n_regions))
data = pd.DataFrame(temperature_data, columns=regions, index=dates)

# Data preprocessing
scaler = MinMaxScaler(feature_range=(0, 1))
scaled_data = scaler.fit_transform(data)

# Function to create sequences for LSTM
def create_sequences(data, time_steps):
    X, y = [], []
    for i in range(len(data) - time_steps):
        X.append(data[i:i + time_steps])
        y.append(data[i + time_steps])
    return np.array(X), np.array(y)

time_steps = 30
X, y = create_sequences(scaled_data, time_steps)

# Reshape data for LSTM
X = X.reshape((X.shape[0], X.shape[1], X.shape[2]))

# LSTM Model
model = Sequential([
    LSTM(64, return_sequences=True, input_shape=(X.shape[1], X.shape[2])),
    LSTM(64),
    Dense(32),
    Dense(n_regions)
])

model.compile(optimizer='adam', loss='mean_squared_error')
model.fit(X, y, batch_size=32, epochs=10, verbose=1)
print("âœ… Model training complete!")

# Dash Layout
app.layout = dbc.Container([
    dbc.Row([
        dbc.Col(html.H1("ğŸŒ¤ Hyperlocal Weather Forecast", className="text-center text-primary mb-4"), width=12)
    ]),

    dbc.Row([
        # Dropdown for region selection
        dbc.Col(
            dbc.Card([
                dbc.CardBody([
                    html.H5("Select a Region", className="card-title"),
                    dcc.Dropdown(
                        id='region-dropdown',
                        options=[{'label': region, 'value': region} for region in regions],
                        value=regions[0],
                        className="mb-2"
                    )
                ])
            ], className="shadow-lg mb-4"), width=4
        ),

        # Temperature Display Box
        dbc.Col(
            dbc.Card([
                dbc.CardBody([
                    html.H5("Predicted Temperature (Â°C)", className="card-title text-center"),
                    html.Div(
                        id="predicted-temp",
                        className="text-center text-warning fs-1 p-3 border border-light rounded",
                        style={"backgroundColor": "#222", "width": "100%", "margin": "auto"}
                    )
                ])
            ], className="shadow-lg mb-4"), width=4
        ),
    ]),

    # Forecast Graph
    dbc.Row([
        dbc.Col(
            dbc.Card([
                dbc.CardBody([
                    dcc.Graph(id='forecast-graph')
                ])
            ], className="shadow-lg mb-4")
        )
    ])
], fluid=True)

# Callback to update forecast graph and predicted temperature
@app.callback(
    [Output('forecast-graph', 'figure'), Output('predicted-temp', 'children')],
    [Input('region-dropdown', 'value')]
)
def update_graph(selected_region):
    try:
        region_index = regions.index(selected_region)
        recent_data = scaled_data[-time_steps:].reshape(1, time_steps, n_regions)

        print("ğŸ” Input shape:", recent_data.shape)

        prediction = model.predict(recent_data)
        print("ğŸ“Š Raw Prediction:", prediction)

        if prediction is not None and len(prediction) > 0:
            region_prediction = prediction[0, region_index]

            # Convert back to real temperature
            region_prediction = scaler.inverse_transform([[region_prediction] * n_regions])[0][region_index]

            print(f"ğŸŒ¡ Final Temperature: {region_prediction:.2f}Â°C")

            # Generate a forecast graph
            fig = px.line(
                x=dates[-time_steps:],
                y=[region_prediction] * time_steps,
                labels={'x': 'Date', 'y': 'Temperature (Â°C)'},
                title=f"Predicted Temperature for {selected_region}"
            )

            return fig, f"{region_prediction:.2f}Â°C"
        else:
            return px.line(title="Error: No prediction generated"), "N/A"

    except Exception as e:
        print(f"âŒ Error: {e}")
        return px.line(title="Error: Unable to generate the graph"), "N/A"

# Run the app
if __name__ == '__main__':
    app.run_server(debug=True)

pip install dash dash-bootstrap-components pandas numpy plotly scikit-learn tensorflow

